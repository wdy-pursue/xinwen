# 🚀 新闻爬取与可视化系统

## 📋 项目概述

这是一个智能新闻爬取与可视化系统，具备以下功能：

### 🕷️ 新闻爬取
- **自动抓取**: 每6小时自动抓取nowhots热门资讯
- **多源支持**: 支持RSS、知乎专栏等多种数据源
- **智能去重**: 基于内容哈希的智能去重机制
- **数据管理**: 自动保留最新200篇文章或7天内数据

### 📱 Web可视化界面
- **美观界面**: 现代化、响应式的Web界面
- **实时展示**: 实时展示最新抓取的新闻资讯
- **多维筛选**: 支持按来源、关键词等维度筛选
- **详情查看**: 点击新闻可查看完整详情
- **进程管理**: 支持start/stop/status命令管理

### 📤 自动发布
- **邮件推送**: 自动发送邮件摘要
- **微信草稿**: 自动创建微信公众号草稿

## 📁 项目结构

```
项目根目录/
├── config.ini                 # 系统配置文件
├── requirements.txt           # Python依赖
├── run_once.sh               # 手动执行爬取脚本
├── start_web.sh              # Web服务器管理脚本
├── src/                      # 源代码目录
│   ├── main.py               # 爬取主程序
│   ├── web_server.py         # Web服务器启动脚本
│   ├── web/                  # Web应用
│   │   ├── app.py            # Flask应用主文件
│   │   ├── api/              # API接口
│   │   │   └── news_api.py   # 新闻API
│   │   ├── static/           # 静态资源
│   │   │   ├── css/          # CSS样式
│   │   │   └── js/           # JavaScript脚本
│   │   └── templates/        # HTML模板
│   │       └── index.html    # 主页面
│   ├── crawlers/             # 爬虫模块
│   ├── models/               # 数据模型
│   ├── publishers/           # 发布模块
│   ├── services/             # 业务服务
│   ├── storage/              # 存储模块
│   └── utils/                # 工具函数
├── data/                     # 数据存储目录
├── logs/                     # 日志目录
└── resources/                # 资源文件
```

## 🚀 快速开始

### 1. 环境准备

确保已安装Python3并配置环境变量：
```bash
python3 --version  # 应该显示Python版本
```

### 2. 安装依赖

```bash
pip3 install -r requirements.txt
```

### 3. 配置系统

编辑 `config.ini` 文件，配置必要信息：
- 微信公众号的 `app_id` 和 `app_secret`
- 邮件发送配置
- 数据管理配置（保留文章数量等）
- 其他API密钥

### 4. 启动服务

#### Web可视化界面管理

**启动Web服务器:**
```bash
./start_web.sh start
```

**查看运行状态:**
```bash
./start_web.sh status
```

**停止Web服务器:**
```bash
./start_web.sh stop
```

**重启Web服务器:**
```bash
./start_web.sh restart
```

**访问地址**: http://localhost:8080 (或 http://your-server-ip:8080)

#### 数据抓取

**手动执行一次爬取:**
```bash
./run_once.sh
```

**设置定时任务:**
```bash
# 编辑crontab
crontab -e

# 添加定时任务（每6小时执行一次）
0 */6 * * * /path/to/your/project/run_once.sh >> /path/to/your/project/logs/cron.log 2>&1
```

## 🌐 Web界面功能

### 📊 主要功能
- **新闻列表**: 展示最新抓取的新闻，支持分页浏览
- **实时搜索**: 在标题中搜索关键词
- **来源筛选**: 按新闻来源进行筛选
- **统计信息**: 显示总文章数、来源数等统计信息
- **新闻详情**: 点击新闻查看完整内容

### 🎨 界面特色
- **现代化设计**: 采用现代化UI设计风格
- **响应式布局**: 支持桌面端和移动端访问
- **美观交互**: 流畅的动画和交互效果
- **数据可视化**: 清晰的数据展示和统计图表

## 🔧 进程管理

### Web服务器管理

```bash
# 启动服务器（后台运行）
./start_web.sh start

# 查看详细状态
./start_web.sh status
# 输出示例：
# ✅ Web服务器正在运行
#    PID: 12345
#    端口: 8080
#    访问地址: http://localhost:8080
#    日志文件: logs/web_server.log
#    网络状态: ✅ 端口监听正常

# 停止服务器
./start_web.sh stop

# 重启服务器
./start_web.sh restart
```

### 日志查看

```bash
# 查看Web服务器日志
tail -f logs/web_server.log

# 查看爬虫日志
tail -f logs/crawler.log

# 查看crontab日志
tail -f logs/cron.log
```

## 🔧 API接口

系统提供RESTful API接口，方便扩展和集成：

### 新闻接口
```bash
GET /api/news                    # 获取新闻列表
GET /api/news/{file_name}        # 获取新闻详情
GET /api/stats                   # 获取统计信息
GET /health                      # 健康检查
```

### 请求参数
- `page`: 页码 (默认: 1)
- `per_page`: 每页数量 (默认: 20, 最大: 100)
- `source`: 来源筛选
- `search`: 搜索关键词

### 响应格式
```json
{
  "success": true,
  "data": {
    "articles": [...],
    "pagination": {...},
    "sources": [...],
    "timestamp": "..."
  }
}
```

## ⚙️ 配置说明

### 数据管理配置
```json
"data_management": {
  "cleanup_enabled": true,    // 是否启用自动清理
  "keep_count": 200,         // 保留文章数量
  "keep_days": 7,            // 保留天数
  "description": "数据管理配置: 保留最新200篇文章或7天内的数据"
}
```

### Web服务配置
```json
"web": {
  "preserve_data": true,     // 保留数据用于展示
  "port": 80,               // 端口号（实际使用8080）
  "description": "Web界面配置: 保留数据用于展示"
}
```

## 🛠️ 定制开发

### 添加新的爬虫
1. 在 `src/crawlers/` 创建新的爬虫类
2. 继承 `BaseCrawler` 并实现 `crawl()` 方法
3. 在 `src/services/crawler_factory.py` 中注册

### 添加新的发布渠道
1. 在 `src/publishers/` 创建新的发布器类
2. 继承 `BasePublisher` 并实现发布方法
3. 在配置文件中添加相应配置

### 自定义Web界面
- 修改 `src/web/templates/index.html` 调整页面结构
- 修改 `src/web/static/css/style.css` 调整样式
- 修改 `src/web/static/js/app.js` 调整交互逻辑

## 📝 常见问题

### Q: Web界面无法访问？
A: 
1. 检查服务器状态: `./start_web.sh status`
2. 确保端口8080开放: `netstat -tlnp | grep :8080`
3. 查看服务器日志: `tail -f logs/web_server.log`

### Q: 没有新闻数据显示？
A: 
1. 先运行 `./run_once.sh` 抓取一些数据
2. 检查 `data/` 目录是否有文章文件
3. 查看日志文件排查问题

### Q: 如何修改保留的文章数量？
A: 
修改 `config.ini` 中的 `data_management.keep_count` 值

### Q: 服务器重启后需要重新启动Web服务吗？
A: 
是的，需要运行 `./start_web.sh start` 重新启动

## 📞 技术支持

如有问题，请检查以下内容：
1. Python环境和依赖安装
2. 配置文件格式和内容
3. 网络连接和防火墙设置
4. 日志文件中的错误信息

## 🎯 系统特色

- ✅ **零硬编码**: 所有配置都在config.ini文件中
- ✅ **智能端口**: 自动检测端口冲突，使用8080端口
- ✅ **进程管理**: 支持标准的start/stop/status命令
- ✅ **后台运行**: Web服务器后台运行，不占用终端
- ✅ **日志记录**: 详细的运行日志和错误记录
- ✅ **自动恢复**: 支持服务重启和状态检查
- ✅ **数据保护**: 智能数据清理，保留最新数据